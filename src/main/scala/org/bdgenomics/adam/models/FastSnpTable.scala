/*
 * Copyright 2019 The Glow Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.bdgenomics.adam.models
import scala.math.{max, min}

import org.apache.spark.sql.SparkSession

/**
 * Creating a SnpTable in ADAM can be very slow. This object constructs an ADAM SnpTable from a
 * Glow DataFrame to take advantage of Glow's faster VCF parser.
 *
 * Note that the order of the contigs in a SnpTable generated by this object differs from one
 * generated by ADAM. ADAM sorts by contig index in the included sequence dictionary while this
 * object sorts by contig name lexicographically. SnpTable lookups work identically, as verified
 * in [[FastSnpTableSuite]].
 */
object FastSnpTable {
  private case class Site(contigName: String, start: Long)

  def fromVcf(spark: SparkSession, path: String): SnpTable = {
    import spark.implicits._

    val variants = spark.read.format("vcf").load(path).as[Site].orderBy("contigName", "start")
    val sortedVariants = variants
      .rdd
      .cache()

    val referenceIndices = sortedVariants
      .map(_.contigName)
      .zipWithIndex
      .mapValues(v => (v.toInt, v.toInt))
      .reduceByKeyLocally((p1, p2) => {
        (min(p1._1, p2._1), max(p1._2, p2._2))
      })
      .toMap
    val sites = sortedVariants.map(_.start: Long).collect()

    // unpersist the cached variants
    sortedVariants.unpersist()
    new SnpTable(referenceIndices, sites)
  }
}
